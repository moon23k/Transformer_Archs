## Transformer_Ablation

The Transformer is a great model, but it's a not perfect model. There's still plenty of room for improvement in Transformer.
This repo compares the three structures, each of **Vanilla**, **Recurrent**, and **Evolved** Transformer. A detailed description of each structure is given below.

<br>
<br>

## Ablations

**Vanilla Transformer**



<br>

**Recurrent Transformer**



<br>

**Evolved Transformer**


<br>
<br>

## Configurations

<br>
<br>

## Result

<br>
<br>

## How to Use

```
git clone https://github.com/moon23k/Transformer_Arhcs.git
```

```
python3 setup.py
```

```
python3 run.py -mode ['train', 'test', 'inference'] -model ['vanilla', 'recurrent', 'evolved']
```

<br>
<br>

## Reference
* [**Attention Is All You Need**](https://arxiv.org/abs/1706.03762) <br>
* [**Universal Transformers**](https://arxiv.org/abs/1807.03819) <br>
* [**The Evolved Transformer**](https://arxiv.org/abs/1901.11117)

<br>
